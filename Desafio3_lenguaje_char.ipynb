{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resolución"
      ],
      "metadata": {
        "id": "BuXlZjf-aLgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alumna: Maria Fabiana Cid"
      ],
      "metadata": {
        "id": "zBbeJ8pvaQ8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo: utilizar la notebook dada en clase para el libro \"Las Mil y una Noches\" extraido  de textos.info\n",
        "\n",
        "Se explora la utilización de SimpleRNN."
      ],
      "metadata": {
        "id": "avXXYolMa8IN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerías:"
      ],
      "metadata": {
        "id": "SLMy2g5YaV3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset el libro Las Mil y una Noches extraido en pdf de textos.info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaKqgfM6w10v",
        "outputId": "5c537b60-541e-4ef1-a113-8f21fa297a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/Anonimo - Las Mil y Una Noches.pdf\"\n",
        "\n",
        "doc = fitz.open(pdf_path)\n",
        "corpus_text = \"\"\n",
        "\n",
        "for page in doc:\n",
        "    corpus_text += page.get_text()\n",
        "\n",
        "print(corpus_text[:1000])  # Ver los primeros caracteres\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw4_-LqLw9bv",
        "outputId": "6107da5e-f222-4949-a488-4b71e0feb654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/24.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/24.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/24.1 MB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m17.9/24.1 MB\u001b[0m \u001b[31m227.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m24.0/24.1 MB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m24.0/24.1 MB\u001b[0m \u001b[31m246.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.0\n",
            "1\n",
            "Las Mil y Una Noches\n",
            "Anónimo\n",
            "textos.info\n",
            "Libros gratis - biblioteca digital abierta\n",
            "2\n",
            "Texto núm. 4140\n",
            "Título: Las Mil y Una Noches\n",
            "Autor: Anónimo\n",
            "Etiquetas: Cuento\n",
            "Editor: Edu Robsy\n",
            "Fecha de creación: 24 de diciembre de 2018\n",
            "Fecha de modificación: 27 de diciembre de 2018\n",
            "Edita textos.info\n",
            "Maison Carrée\n",
            "c/ Ramal, 48\n",
            "07730 Alayor - Menorca\n",
            "Islas Baleares\n",
            "España\n",
            "Más textos disponibles en http://www.textos.info\n",
            "3\n",
            "Una palabra del traductor a sus amigos\n",
            "Yo ofrezco\n",
            "desnudas, vírgenes, intactas y sencillas,\n",
            "para mis delicias y el placer de mis amigos,\n",
            "estas noches árabes vividas, soñadas y traducidas sobre su tierra natal y \n",
            "sobre el agua\n",
            "Ellas me fueron dulces durante los ocios en remotos mares, bajo un cielo \n",
            "ahora lejano.\n",
            "Por eso las doy.\n",
            "Sencillas, sonrientes y llenas de ingenuidad, como la musulmana \n",
            "Schehrazada, su madre suculenta que las dió a luz en el misterio; \n",
            "fermentando con emoción en los brazos de un príncipe sublime —lúbrico y \n",
            "feroz—, bajo la mirada enternecida de Alah, cleme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar: minúsculas, eliminar caracteres raros\n",
        "corpus_text = corpus_text.lower()\n",
        "corpus_text = re.sub(r'[^a-záéíóúüñ\\s]', '', corpus_text)\n"
      ],
      "metadata": {
        "id": "RnE7XmIIy3tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(corpus_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ce67ec-08a5-44ef-ffae-d468171146d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in corpus_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwGVSKOiJ5bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca814ea-c267-46ed-88f9-a5022acffb8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 6,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 4,\n",
              " 25,\n",
              " 8,\n",
              " 34,\n",
              " 25,\n",
              " 9,\n",
              " 20,\n",
              " 24,\n",
              " 5,\n",
              " 23,\n",
              " 10,\n",
              " 8,\n",
              " 25,\n",
              " 31,\n",
              " 25,\n",
              " 17,\n",
              " 0,\n",
              " 9,\n",
              " 10,\n",
              " 29,\n",
              " 5,\n",
              " 12,\n",
              " 29,\n",
              " 9,\n",
              " 23,\n",
              " 17,\n",
              " 25,\n",
              " 22,\n",
              " 9,\n",
              " 10,\n",
              " 6,\n",
              " 17,\n",
              " 30,\n",
              " 19,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 26,\n",
              " 19,\n",
              " 8,\n",
              " 29,\n",
              " 17,\n",
              " 23,\n",
              " 34,\n",
              " 34,\n",
              " 30,\n",
              " 17,\n",
              " 30,\n",
              " 6,\n",
              " 17,\n",
              " 9,\n",
              " 29,\n",
              " 5,\n",
              " 20,\n",
              " 8,\n",
              " 34,\n",
              " 32,\n",
              " 17,\n",
              " 26,\n",
              " 17,\n",
              " 29,\n",
              " 8,\n",
              " 6,\n",
              " 34,\n",
              " 8,\n",
              " 30,\n",
              " 17,\n",
              " 5,\n",
              " 19,\n",
              " 29,\n",
              " 8,\n",
              " 10,\n",
              " 10,\n",
              " 29,\n",
              " 5,\n",
              " 12,\n",
              " 29,\n",
              " 9,\n",
              " 34,\n",
              " 25,\n",
              " 21,\n",
              " 0,\n",
              " 34,\n",
              " 10,\n",
              " 29,\n",
              " 16,\n",
              " 29,\n",
              " 4,\n",
              " 6,\n",
              " 9,\n",
              " 34,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 6,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 4,\n",
              " 25,\n",
              " 8,\n",
              " 34,\n",
              " 25,\n",
              " 9,\n",
              " 20,\n",
              " 24,\n",
              " 5,\n",
              " 23,\n",
              " 10,\n",
              " 8,\n",
              " 4,\n",
              " 29,\n",
              " 9,\n",
              " 19,\n",
              " 34,\n",
              " 8,\n",
              " 25,\n",
              " 31,\n",
              " 25,\n",
              " 17,\n",
              " 0,\n",
              " 9,\n",
              " 10,\n",
              " 5,\n",
              " 29,\n",
              " 17,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 29,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 20,\n",
              " 4,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 9,\n",
              " 10,\n",
              " 5,\n",
              " 32,\n",
              " 17,\n",
              " 29,\n",
              " 9,\n",
              " 19,\n",
              " 34,\n",
              " 5,\n",
              " 32,\n",
              " 4,\n",
              " 34,\n",
              " 19,\n",
              " 9,\n",
              " 30,\n",
              " 23,\n",
              " 3,\n",
              " 10,\n",
              " 22,\n",
              " 5,\n",
              " 20,\n",
              " 24,\n",
              " 8,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 20,\n",
              " 19,\n",
              " 5,\n",
              " 8,\n",
              " 20,\n",
              " 17,\n",
              " 31,\n",
              " 25,\n",
              " 34,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 32,\n",
              " 17,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 0,\n",
              " 30,\n",
              " 19,\n",
              " 5,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 10,\n",
              " 22,\n",
              " 5,\n",
              " 20,\n",
              " 24,\n",
              " 8,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 0,\n",
              " 9,\n",
              " 32,\n",
              " 17,\n",
              " 22,\n",
              " 17,\n",
              " 20,\n",
              " 8,\n",
              " 20,\n",
              " 17,\n",
              " 31,\n",
              " 25,\n",
              " 34,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 32,\n",
              " 17,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 0,\n",
              " 30,\n",
              " 19,\n",
              " 5,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 10,\n",
              " 5,\n",
              " 32,\n",
              " 17,\n",
              " 29,\n",
              " 8,\n",
              " 34,\n",
              " 29,\n",
              " 5,\n",
              " 12,\n",
              " 29,\n",
              " 9,\n",
              " 23,\n",
              " 17,\n",
              " 25,\n",
              " 22,\n",
              " 9,\n",
              " 10,\n",
              " 0,\n",
              " 8,\n",
              " 17,\n",
              " 23,\n",
              " 9,\n",
              " 25,\n",
              " 34,\n",
              " 20,\n",
              " 8,\n",
              " 19,\n",
              " 19,\n",
              " 13,\n",
              " 5,\n",
              " 10,\n",
              " 20,\n",
              " 34,\n",
              " 19,\n",
              " 8,\n",
              " 0,\n",
              " 8,\n",
              " 6,\n",
              " 34,\n",
              " 10,\n",
              " 34,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 3,\n",
              " 9,\n",
              " 19,\n",
              " 34,\n",
              " 34,\n",
              " 0,\n",
              " 5,\n",
              " 25,\n",
              " 9,\n",
              " 19,\n",
              " 20,\n",
              " 8,\n",
              " 10,\n",
              " 17,\n",
              " 23,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 30,\n",
              " 8,\n",
              " 6,\n",
              " 5,\n",
              " 8,\n",
              " 19,\n",
              " 5,\n",
              " 23,\n",
              " 10,\n",
              " 5,\n",
              " 23,\n",
              " 2,\n",
              " 8,\n",
              " 27,\n",
              " 8,\n",
              " 10,\n",
              " 0,\n",
              " 1,\n",
              " 23,\n",
              " 34,\n",
              " 29,\n",
              " 5,\n",
              " 12,\n",
              " 29,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 17,\n",
              " 23,\n",
              " 2,\n",
              " 9,\n",
              " 25,\n",
              " 17,\n",
              " 30,\n",
              " 6,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 5,\n",
              " 25,\n",
              " 34,\n",
              " 24,\n",
              " 29,\n",
              " 29,\n",
              " 2,\n",
              " 18,\n",
              " 18,\n",
              " 18,\n",
              " 29,\n",
              " 5,\n",
              " 12,\n",
              " 29,\n",
              " 9,\n",
              " 23,\n",
              " 17,\n",
              " 25,\n",
              " 22,\n",
              " 9,\n",
              " 10,\n",
              " 10,\n",
              " 4,\n",
              " 25,\n",
              " 8,\n",
              " 34,\n",
              " 2,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 30,\n",
              " 19,\n",
              " 8,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 6,\n",
              " 34,\n",
              " 29,\n",
              " 19,\n",
              " 8,\n",
              " 32,\n",
              " 4,\n",
              " 20,\n",
              " 29,\n",
              " 9,\n",
              " 19,\n",
              " 34,\n",
              " 8,\n",
              " 34,\n",
              " 23,\n",
              " 4,\n",
              " 23,\n",
              " 34,\n",
              " 8,\n",
              " 0,\n",
              " 17,\n",
              " 26,\n",
              " 9,\n",
              " 23,\n",
              " 10,\n",
              " 3,\n",
              " 9,\n",
              " 34,\n",
              " 9,\n",
              " 22,\n",
              " 19,\n",
              " 5,\n",
              " 28,\n",
              " 20,\n",
              " 9,\n",
              " 10,\n",
              " 32,\n",
              " 5,\n",
              " 23,\n",
              " 25,\n",
              " 4,\n",
              " 32,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 15,\n",
              " 16,\n",
              " 19,\n",
              " 26,\n",
              " 5,\n",
              " 25,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 17,\n",
              " 25,\n",
              " 29,\n",
              " 8,\n",
              " 20,\n",
              " 29,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 23,\n",
              " 5,\n",
              " 25,\n",
              " 20,\n",
              " 17,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 10,\n",
              " 2,\n",
              " 8,\n",
              " 19,\n",
              " 8,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 6,\n",
              " 17,\n",
              " 20,\n",
              " 17,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 5,\n",
              " 6,\n",
              " 34,\n",
              " 2,\n",
              " 6,\n",
              " 8,\n",
              " 20,\n",
              " 5,\n",
              " 19,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 23,\n",
              " 34,\n",
              " 8,\n",
              " 0,\n",
              " 17,\n",
              " 26,\n",
              " 9,\n",
              " 23,\n",
              " 10,\n",
              " 5,\n",
              " 23,\n",
              " 29,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 25,\n",
              " 9,\n",
              " 20,\n",
              " 24,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 1,\n",
              " 19,\n",
              " 8,\n",
              " 30,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 15,\n",
              " 17,\n",
              " 15,\n",
              " 17,\n",
              " 32,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 23,\n",
              " 9,\n",
              " 27,\n",
              " 8,\n",
              " 32,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 29,\n",
              " 19,\n",
              " 8,\n",
              " 32,\n",
              " 4,\n",
              " 20,\n",
              " 17,\n",
              " 32,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 23,\n",
              " 9,\n",
              " 30,\n",
              " 19,\n",
              " 5,\n",
              " 34,\n",
              " 23,\n",
              " 4,\n",
              " 34,\n",
              " 29,\n",
              " 17,\n",
              " 5,\n",
              " 19,\n",
              " 19,\n",
              " 8,\n",
              " 34,\n",
              " 25,\n",
              " 8,\n",
              " 29,\n",
              " 8,\n",
              " 6,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 10,\n",
              " 23,\n",
              " 9,\n",
              " 30,\n",
              " 19,\n",
              " 5,\n",
              " 34,\n",
              " 5,\n",
              " 6,\n",
              " 34,\n",
              " 8,\n",
              " 26,\n",
              " 4,\n",
              " 8,\n",
              " 10,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 0,\n",
              " 5,\n",
              " 34,\n",
              " 22,\n",
              " 4,\n",
              " 5,\n",
              " 19,\n",
              " 9,\n",
              " 25,\n",
              " 34,\n",
              " 32,\n",
              " 4,\n",
              " 6,\n",
              " 20,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 4,\n",
              " 19,\n",
              " 8,\n",
              " 25,\n",
              " 29,\n",
              " 5,\n",
              " 34,\n",
              " 6,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 9,\n",
              " 20,\n",
              " 17,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 5,\n",
              " 25,\n",
              " 34,\n",
              " 19,\n",
              " 5,\n",
              " 0,\n",
              " 9,\n",
              " 29,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 0,\n",
              " 8,\n",
              " 19,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 30,\n",
              " 8,\n",
              " 11,\n",
              " 9,\n",
              " 34,\n",
              " 4,\n",
              " 25,\n",
              " 34,\n",
              " 20,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 9,\n",
              " 34,\n",
              " 10,\n",
              " 8,\n",
              " 24,\n",
              " 9,\n",
              " 19,\n",
              " 8,\n",
              " 34,\n",
              " 6,\n",
              " 5,\n",
              " 11,\n",
              " 8,\n",
              " 25,\n",
              " 9,\n",
              " 10,\n",
              " 2,\n",
              " 9,\n",
              " 19,\n",
              " 34,\n",
              " 5,\n",
              " 23,\n",
              " 9,\n",
              " 34,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 9,\n",
              " 3,\n",
              " 10,\n",
              " 23,\n",
              " 5,\n",
              " 25,\n",
              " 20,\n",
              " 17,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 23,\n",
              " 9,\n",
              " 25,\n",
              " 19,\n",
              " 17,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 5,\n",
              " 23,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 6,\n",
              " 6,\n",
              " 5,\n",
              " 25,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 17,\n",
              " 25,\n",
              " 26,\n",
              " 5,\n",
              " 25,\n",
              " 4,\n",
              " 17,\n",
              " 32,\n",
              " 8,\n",
              " 32,\n",
              " 34,\n",
              " 20,\n",
              " 9,\n",
              " 0,\n",
              " 9,\n",
              " 34,\n",
              " 6,\n",
              " 8,\n",
              " 34,\n",
              " 0,\n",
              " 4,\n",
              " 23,\n",
              " 4,\n",
              " 6,\n",
              " 0,\n",
              " 8,\n",
              " 25,\n",
              " 8,\n",
              " 34,\n",
              " 10,\n",
              " 23,\n",
              " 20,\n",
              " 24,\n",
              " 5,\n",
              " 24,\n",
              " 19,\n",
              " 8,\n",
              " 28,\n",
              " 8,\n",
              " 32,\n",
              " 8,\n",
              " 34,\n",
              " 23,\n",
              " 4,\n",
              " 34,\n",
              " 0,\n",
              " 8,\n",
              " 32,\n",
              " 19,\n",
              " 5,\n",
              " 34,\n",
              " 23,\n",
              " 4,\n",
              " 20,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 8,\n",
              " 34,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 34,\n",
              " 6,\n",
              " 8,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 17,\n",
              " 31,\n",
              " 34,\n",
              " 8,\n",
              " 34,\n",
              " 6,\n",
              " 4,\n",
              " 28,\n",
              " 34,\n",
              " 5,\n",
              " 25,\n",
              " 34,\n",
              " 5,\n",
              " 6,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 23,\n",
              " 29,\n",
              " 5,\n",
              " 19,\n",
              " 17,\n",
              " 9,\n",
              " 34,\n",
              " 10,\n",
              " 22,\n",
              " 5,\n",
              " 19,\n",
              " 0,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 8,\n",
              " 25,\n",
              " 32,\n",
              " 9,\n",
              " 34,\n",
              " 20,\n",
              " 9,\n",
              " 25,\n",
              " 34,\n",
              " 5,\n",
              " 0,\n",
              " 9,\n",
              " 20,\n",
              " 17,\n",
              " 31,\n",
              " 25,\n",
              " 34,\n",
              " 5,\n",
              " 25,\n",
              " 34,\n",
              " 6,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 30,\n",
              " 19,\n",
              " 8,\n",
              " 28,\n",
              " 9,\n",
              " 23,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 4,\n",
              " 25,\n",
              " 34,\n",
              " 2,\n",
              " 19,\n",
              " 16,\n",
              " 25,\n",
              " 20,\n",
              " 17,\n",
              " 2,\n",
              " 5,\n",
              " 34,\n",
              " 23,\n",
              " 4,\n",
              " 30,\n",
              " 6,\n",
              " 17,\n",
              " 0,\n",
              " 5,\n",
              " 34,\n",
              " 6,\n",
              " 21,\n",
              " 30,\n",
              " 19,\n",
              " 17,\n",
              " 20,\n",
              " 9,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 10,\n",
              " 22,\n",
              " 5,\n",
              " 19,\n",
              " 9,\n",
              " 28,\n",
              " 34,\n",
              " 30,\n",
              " 8,\n",
              " 11,\n",
              " 9,\n",
              " 34,\n",
              " 6,\n",
              " 8,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 19,\n",
              " 8,\n",
              " 32,\n",
              " 8,\n",
              " 34,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 5,\n",
              " 19,\n",
              " 25,\n",
              " 5,\n",
              " 20,\n",
              " 17,\n",
              " 32,\n",
              " 8,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 34,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 24,\n",
              " 34,\n",
              " 20,\n",
              " 6,\n",
              " 5,\n",
              " 0,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 5,\n",
              " 34,\n",
              " 3,\n",
              " 34,\n",
              " 0,\n",
              " 17,\n",
              " 23,\n",
              " 5,\n",
              " 19,\n",
              " 17,\n",
              " 20,\n",
              " 9,\n",
              " 19,\n",
              " 32,\n",
              " 17,\n",
              " 9,\n",
              " 23,\n",
              " 9,\n",
              " 10,\n",
              " 8,\n",
              " 6,\n",
              " 34,\n",
              " 15,\n",
              " 5,\n",
              " 25,\n",
              " 17,\n",
              " 19,\n",
              " 34,\n",
              " 8,\n",
              " 6,\n",
              " 34,\n",
              " 0,\n",
              " 4,\n",
              " 25,\n",
              " 32,\n",
              " 9,\n",
              " 34,\n",
              " 22,\n",
              " 4,\n",
              " 5,\n",
              " 19,\n",
              " 9,\n",
              " 25,\n",
              " 34,\n",
              " 32,\n",
              " 5,\n",
              " 6,\n",
              " 17,\n",
              " 20,\n",
              " 8,\n",
              " 32,\n",
              " 8,\n",
              " 0,\n",
              " 5,\n",
              " 25,\n",
              " 29,\n",
              " 5,\n",
              " 34]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFAyA4zCWE-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb8575e-4f41-4db6-9f62-370c29796da5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6017806, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcKRl70HFTzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256dd179-50b9-4b22-d2b2-eba7c5f0a557"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10,  6,  8, 23, 34,  0, 17,  6, 34,  3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVpLCKSZFXZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab58c13c-83ab-4fdf-b03f-e9fb8c1d552c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  8, 23, 34,  0, 17,  6, 34,  3, 34])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd2OkfQYs2Q7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "a8c3ec04-3d85-4987-bd6b-dda16ceeeb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m47,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)       │         \u001b[38;5;34m7,035\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,035</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,235\u001b[0m (211.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,235</span> (211.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,235\u001b[0m (211.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,235</span> (211.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sepjH-J9YAq7"
      },
      "outputs": [],
      "source": [
        "class PerplexityCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=None):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Calculate and log training perplexity\n",
        "        train_loss = logs.get('loss')\n",
        "        if train_loss is not None:\n",
        "            train_perplexity = np.exp(train_loss)\n",
        "            print(f'\\nTraining Perplexity: {train_perplexity:.4f}')\n",
        "            logs['perplexity'] = train_perplexity\n",
        "\n",
        "        # Calculate validation perplexity if validation data exists\n",
        "        if self.validation_data is not None:\n",
        "            val_loss = logs.get('val_loss')\n",
        "            if val_loss is not None:\n",
        "                val_perplexity = np.exp(val_loss)\n",
        "                print(f'Validation Perplexity: {val_perplexity:.4f}')\n",
        "                logs['val_perplexity'] = val_perplexity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQq1PHDkxDvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5cc25d-fb86-4059-9350-a56f386de05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8776\n",
            "Training Perplexity: 5.7987\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 11ms/step - loss: 1.8776 - perplexity: 5.7987\n",
            "Epoch 2/20\n",
            "\u001b[1m20059/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6752\n",
            "Training Perplexity: 5.3115\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 10ms/step - loss: 1.6752 - perplexity: 5.3115\n",
            "Epoch 3/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6587\n",
            "Training Perplexity: 5.2399\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 10ms/step - loss: 1.6587 - perplexity: 5.2399\n",
            "Epoch 4/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6508\n",
            "Training Perplexity: 5.2034\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 10ms/step - loss: 1.6508 - perplexity: 5.2034\n",
            "Epoch 5/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6458\n",
            "Training Perplexity: 5.1803\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6458 - perplexity: 5.1803\n",
            "Epoch 6/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6423\n",
            "Training Perplexity: 5.1643\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 11ms/step - loss: 1.6423 - perplexity: 5.1643\n",
            "Epoch 7/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6400\n",
            "Training Perplexity: 5.1530\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 10ms/step - loss: 1.6400 - perplexity: 5.1530\n",
            "Epoch 8/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6382\n",
            "Training Perplexity: 5.1437\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 10ms/step - loss: 1.6382 - perplexity: 5.1437\n",
            "Epoch 9/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6367\n",
            "Training Perplexity: 5.1369\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 10ms/step - loss: 1.6367 - perplexity: 5.1369\n",
            "Epoch 10/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6355\n",
            "Training Perplexity: 5.1309\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 11ms/step - loss: 1.6355 - perplexity: 5.1309\n",
            "Epoch 11/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6343\n",
            "Training Perplexity: 5.1251\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 11ms/step - loss: 1.6343 - perplexity: 5.1251\n",
            "Epoch 12/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6340\n",
            "Training Perplexity: 5.1219\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 11ms/step - loss: 1.6340 - perplexity: 5.1219\n",
            "Epoch 13/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6330\n",
            "Training Perplexity: 5.1177\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 11ms/step - loss: 1.6330 - perplexity: 5.1177\n",
            "Epoch 14/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6323\n",
            "Training Perplexity: 5.1142\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6323 - perplexity: 5.1142\n",
            "Epoch 15/20\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6314\n",
            "Training Perplexity: 5.1111\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 11ms/step - loss: 1.6314 - perplexity: 5.1111\n",
            "Epoch 16/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6311\n",
            "Training Perplexity: 5.1088\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6311 - perplexity: 5.1088\n",
            "Epoch 17/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6307\n",
            "Training Perplexity: 5.1070\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6307 - perplexity: 5.1070\n",
            "Epoch 18/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6306\n",
            "Training Perplexity: 5.1059\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 11ms/step - loss: 1.6306 - perplexity: 5.1059\n",
            "Epoch 19/20\n",
            "\u001b[1m20056/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6298\n",
            "Training Perplexity: 5.1027\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6298 - perplexity: 5.1027\n",
            "Epoch 20/20\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6297\n",
            "Training Perplexity: 5.1020\n",
            "\u001b[1m20060/20060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 11ms/step - loss: 1.6297 - perplexity: 5.1020\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, mientras más grande mejor.\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PerplexityCallback(tokenized_sentences_val)],  batch_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA2qRjVaR_gk"
      },
      "outputs": [],
      "source": [
        "model.save('my_model_3.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('/content/my_model_3.keras')"
      ],
      "metadata": {
        "id": "QgJEC_5uQt_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBvKHFPmzpy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3201a7-3976-4adb-c3a3-a2b66d1903cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNyBykvhzs7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "1d3296ca-97c4-4f07-91d2-290c4ac23487"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ed36db241d96e6bc9e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ed36db241d96e6bc9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ed36db241d96e6bc9e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d8f3e710-8958-4844-89bf-d5fb7b9ad171"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'habia una vez y el califa y el califa y el '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "input_text='habia una vez'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"habia una vez\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8HQoLhw-NYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089d60cf-7f17-493c-d65e-4569c4890aa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24,  8, 30, 17,  8, 34,  4, 25,  8, 34, 15,  5, 28, 34,  7,  4,  5,\n",
              "       34, 23,  5, 34, 20,  8,  6,  6, 31, 34, 32, 17, 23, 20, 19,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S3_I3S1W1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1b1c4f27-9842-4ae8-a866-64509e0eb5ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'habia una vez que se calló discre'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo entiende estructuras narrativas, pero la generación fue interrumpida o desestabilizada por el muestreo. Vamos a probar una segunda opción con uso de LSTM."
      ],
      "metadata": {
        "id": "CXKY9anncg41"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}